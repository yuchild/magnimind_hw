{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "#from scipy import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/auto_scout_clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m auto_org \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/auto_scout_clean.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/auto_scout_clean.csv'"
     ]
    }
   ],
   "source": [
    "auto_org = pd.read_csv('./data/auto_scout_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = auto_org.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## body_type column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.body_type.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[auto.body_type.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[auto.make_model == 'Opel Astra']['body_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.groupby('make_model')['body_type'].transform(lambda x: x.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[\"body_type\"].fillna(auto.groupby('make_model')['body_type'].transform(lambda x: x.mode()[0]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto[\"body_type\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* body_type column was filled with most frequent values of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## year column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.loc[((auto['new_used'] == 'New') & auto.year.isnull()), 'year'] = 2019 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.year.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = auto[(auto['make_model'] == 'Audi A1') & (auto['body_type'] == 'Compact')].groupby('year').km.mean()\n",
    "std = auto[(auto['make_model'] == 'Audi A1') & (auto['body_type'] == 'Compact')].groupby('year').km.std()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_fill(year,km,mean,std):\n",
    "    if pd.isna(year):\n",
    "        for i in range(len(mean.values)):\n",
    "            if mean.index[i] == 2016:\n",
    "                if km >= (mean.values[i]-(std.values[i])):\n",
    "                    return 2016\n",
    "            if mean.index[i] == 2017:\n",
    "                if (km >= (mean.values[i]-std.values[i])) | (km <= (mean.values[i]+std.values[i])):\n",
    "                    return 2017\n",
    "            if mean.index[i] == 2018:\n",
    "                if (km >= (mean.values[i]-std.values[i])) | (km <= (mean.values[i]+std.values[i])):\n",
    "                    return 2018\n",
    "            if mean.index[i] == 2019:\n",
    "                if km <= (mean.values[i]+std.values[i]):\n",
    "                    return 2019\n",
    "    else:\n",
    "        return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_fill(year,price,mean,std):\n",
    "    if pd.isna(year):\n",
    "        for i in range(len(mean.values)):\n",
    "            if mean.index[i] == 2019:\n",
    "                if price >= (mean.values[i]-(std.values[i])):\n",
    "                    return 2019\n",
    "            if mean.index[i] == 2018:\n",
    "                if (price >= (mean.values[i]-std.values[i])) | (price <= (mean.values[i]+std.values[i])):\n",
    "                    return 2018\n",
    "            if mean.index[i] == 2017:\n",
    "                if (price >= (mean.values[i]-std.values[i])) | (price <= (mean.values[i]+std.values[i])):\n",
    "                    return 2017\n",
    "            if mean.index[i] == 2016:\n",
    "                if price <= (mean.values[i]+std.values[i]):\n",
    "                    return 2016\n",
    "    else:\n",
    "        return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group1 in list(auto['make_model'].unique()):\n",
    "    for group2 in list(auto['body_type'].unique()):\n",
    "        cond1 = auto['make_model'] == group1\n",
    "        cond2 = auto['body_type'] == group2\n",
    "        mean = auto[cond1 & cond2].groupby('year').km.mean()\n",
    "        std = auto[cond1 & cond2].groupby('year').km.std()\n",
    "        auto.loc[cond1 & cond2, 'year'] = (auto[cond1 & cond2]\n",
    "                                  .apply(lambda x: year_fill(x['year'],x['km'],mean,std),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group1 in list(auto['make_model'].unique()):\n",
    "    for group2 in list(auto['body_type'].unique()):\n",
    "        cond1 = auto['make_model'] == group1\n",
    "        cond2 = auto['body_type'] == group2\n",
    "        mean = auto[cond1 & cond2].groupby('year').price.mean()\n",
    "        std = auto[cond1 & cond2].groupby('year').price.std()\n",
    "        auto.loc[cond1 & cond2, 'year'] = (auto[cond1 & cond2]\n",
    "                                  .apply(lambda x: year_fill(x['year'],x['price'],mean,std),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto[auto.year.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.year.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## km column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_group_km = auto.groupby(['make_model','body_type','year']).km.transform(lambda x: x.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[\"km\"].fillna(mean_group_km, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.km.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[auto.km.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[\"km\"].fillna(auto.groupby(['make_model','year']).km.transform(lambda x: x.median()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.km.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prev_owner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto.new_used.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=auto[auto[\"km\"]<100].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.loc[(auto['new_used'] == 'New') & (auto['km']>3000),'new_used'] = 'Used'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.loc[index,\"prev_owner\"]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.loc[(auto[\"new_used\"]==\"New\") & (auto[\"prev_owner\"].isnull()),\"prev_owner\"]=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.loc[((auto[\"year\"]==2019) | (auto[\"km\"]<5000)) & (auto[\"prev_owner\"].isnull()),\"prev_owner\"]=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_group_po = auto.groupby(['year'])['prev_owner'].transform(lambda x: x.mode()[0] if list(x.mode()) != [] else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[\"prev_owner\"].fillna(mode_group_po, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto['prev_owner'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto['prev_owner'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[auto.hp.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[auto.make_model == 'Opel Astra'][['body_type','hp', 'displacement']].sort_values(by=['body_type','displacement']).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_hp = auto[~(auto['displacement'].isnull())]\\\n",
    "              .groupby(['make_model','body_type','displacement'])['hp']\\\n",
    "              .transform(lambda x: x.mode()[0] if list(x.mode()) != [] else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.loc[~(auto['displacement'].isnull()),\"hp\"] = auto.loc[~(auto['displacement'].isnull()),\"hp\"].fillna(mode_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_hp1 = auto[~(auto['displacement'].isnull())]\\\n",
    "              .groupby(['make_model','displacement'])['hp']\\\n",
    "              .transform(lambda x: x.mode()[0] if list(x.mode()) != [] else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.loc[~(auto['displacement'].isnull()),\"hp\"] = auto.loc[~(auto['displacement'].isnull()),\"hp\"].fillna(mode_hp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_hp2 = auto[~(auto['displacement'].isnull())]\\\n",
    "              .groupby(['make_model','body_type'])['hp']\\\n",
    "              .transform(lambda x: x.mode()[0] if list(x.mode()) != [] else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[\"hp\"] = auto[\"hp\"].fillna(mode_hp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_hp2 = auto.groupby(['make_model','body_type'])['hp']\\\n",
    "              .transform(lambda x: x.mode()[0] if list(x.mode()) != [] else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[\"hp\"] = auto[\"hp\"].fillna(mode_hp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_hp3 = auto.groupby(['make_model'])['hp']\\\n",
    "              .transform(lambda x: x.mode()[0] if list(x.mode()) != [] else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[\"hp\"] = auto[\"hp\"].fillna(mode_hp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[\"hp\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## warranty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[auto.warranty.isnull()].year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[\"warranty\"] = auto[\"warranty\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.warranty.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### warranty column was filled with 0's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## body color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto['body_color'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_color = auto.groupby(['make_model','body_type'])['body_color']\\\n",
    "              .transform(lambda x: x.mode()[0] if list(x.mode()) != [] else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[\"body_color\"] = auto[\"body_color\"].fillna(mode_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_color2 = auto.groupby(['make_model'])['body_color']\\\n",
    "              .transform(lambda x: x.mode()[0] if list(x.mode()) != [] else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[\"body_color\"] = auto[\"body_color\"].fillna(mode_color2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto['body_color'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "model = ols('price ~ C(consumption_comb)', data=auto).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.corr()['price'].sort_values()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "m_qcut = df[[\"km\"]]\n",
    "df[\"m_qcut\"] = pd.qcut(m_qcut[\"km\"], q = 15)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df[\"m_qcut\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#We filled in our categorical data\n",
    "fill_most(miss_df,‘make-model’,‘body_type’)\n",
    "fill_most(miss_df,‘make-model’,‘drivetrain’)\n",
    "fill_most(miss_df,‘make-model’,‘type’)\n",
    "fill_most(miss_df,‘make-model’,‘colour’)\n",
    "fill_most(miss_df,‘make-model’,‘upholstery’)\n",
    "fill(miss_df,‘make-model’,‘body_type’, ‘gearbox’, ‘mode’)\n",
    "# We filled in our numerical data\n",
    "boolean = True\n",
    "count = 0\n",
    "while boolean:\n",
    "    count += 1\n",
    "    total_miss_numbers = miss_df[[‘gearbox’,‘seats’,‘Power’,‘doors’,‘warranty_months’,‘engine_size’,‘gears’,‘cylinders’,‘empty_weight’,‘fuel_consumption’,‘co2_emissions’,‘general_inspection_new’]].isnull().sum().sum()\n",
    "    if total_miss_numbers == 0:\n",
    "        boolean = False\n",
    "    if count == 10:\n",
    "        boolean = False\n",
    "    else:\n",
    "        miss_df[‘doors’] = miss_df[‘doors’].fillna(miss_df.groupby([‘make-model’])[‘doors’].transform(‘median’))\n",
    "        miss_df[‘seats’] = miss_df[‘seats’].fillna(miss_df.groupby([‘make-model’])[‘seats’].transform(‘median’))\n",
    "        miss_df[‘Power’] = miss_df[‘Power’].fillna(miss_df.groupby([‘es_qcut’,‘ew_qcut’])[‘Power’].transform(‘median’))\n",
    "        miss_df[‘Power’] = miss_df[‘Power’].fillna(miss_df.groupby([‘fc_qcut’,‘ew_qcut’])[‘Power’].transform(‘median’))\n",
    "        miss_df[‘Power’] = miss_df[‘Power’].fillna(miss_df.groupby([‘fc_qcut’,‘es_qcut’])[‘Power’].transform(‘median’))\n",
    "        miss_df[‘Power’] = miss_df[‘Power’].fillna(miss_df.groupby([‘ew_qcut’])[‘Power’].transform(‘median’))\n",
    "        miss_df[‘Power’] = miss_df[‘Power’].fillna(miss_df.groupby([‘es_qcut’])[‘Power’].transform(‘median’))\n",
    "        miss_df[‘Power’] = miss_df[‘Power’].fillna(miss_df.groupby([‘make-model’])[‘Power’].transform(‘median’))\n",
    "        miss_df[‘engine_size’] = miss_df[‘engine_size’].fillna(miss_df.groupby([‘cylinders’])[‘engine_size’].transform(‘median’))\n",
    "        miss_df[‘gears’] = miss_df[‘gears’].fillna(miss_df.groupby([‘make-model’])[‘gears’].transform(‘median’))\n",
    "        miss_df[‘cylinders’] = miss_df[‘cylinders’].fillna(miss_df.groupby([‘make-model’])[‘cylinders’].transform(‘median’))\n",
    "        miss_df[‘cylinders’] = miss_df[‘cylinders’].fillna(miss_df.groupby([‘es_qcut’])[‘cylinders’].transform(‘median’))\n",
    "        miss_df[‘cylinders’] = miss_df[‘cylinders’].fillna(miss_df.groupby([‘gears’])[‘cylinders’].transform(‘median’))\n",
    "        miss_df[‘empty_weight’] = miss_df[‘empty_weight’].fillna(miss_df.groupby([‘make-model’])[‘empty_weight’].transform(‘median’))\n",
    "        miss_df[‘fuel_consumption’] = miss_df[‘fuel_consumption’].fillna(miss_df.groupby([‘es_qcut’])[‘fuel_consumption’].transform(‘median’))\n",
    "        miss_df[‘fuel_consumption’] = miss_df[‘fuel_consumption’].fillna(miss_df.groupby([‘co_qcut’])[‘fuel_consumption’].transform(‘median’))\n",
    "        miss_df[‘fuel_consumption’] = miss_df[‘fuel_consumption’].fillna(miss_df.groupby([‘cylinders’])[‘fuel_consumption’].transform(‘median’))\n",
    "        miss_df[‘fuel_consumption’] = miss_df[‘fuel_consumption’].fillna(miss_df.groupby([‘ew_qcut’])[‘fuel_consumption’].transform(‘median’))\n",
    "        miss_df[‘co2_emissions’] = miss_df[‘co2_emissions’].fillna(miss_df.groupby([‘fc_qcut’])[‘co2_emissions’].transform(‘median’))\n",
    "        miss_df[‘co2_emissions’] = miss_df[‘co2_emissions’].fillna(miss_df.groupby([‘cylinders’])[‘co2_emissions’].transform(‘median’))\n",
    "        miss_df[‘co2_emissions’] = miss_df[‘co2_emissions’].fillna(miss_df.groupby([‘make-model’])[‘co2_emissions’].transform(‘median’))\n",
    "        miss_df[‘co2_emissions’] = miss_df[‘co2_emissions’].fillna(miss_df.groupby([‘p_qcut’])[‘co2_emissions’].transform(‘median’))\n",
    "        miss_df[‘first_registration_years’] = miss_df[‘first_registration_years’].fillna(miss_df.groupby([‘mileage’])[‘first_registration_years’].transform(‘median’))\n",
    "        miss_df[‘first_registration_years’] = miss_df[‘first_registration_years’].fillna(miss_df.groupby([‘co_qcut’,‘m_qcut’])[‘first_registration_years’].transform(‘median’))\n",
    "        miss_df[‘first_registration_years’] = miss_df[‘first_registration_years’].fillna(miss_df.groupby([‘fuel_type’])[‘first_registration_years’].transform(‘median’))\n",
    "        miss_df[‘mileage’] = miss_df[‘mileage’].fillna(miss_df.groupby([‘fry_qcut’,‘general_inspection_new’])[‘mileage’].transform(‘mean’))\n",
    "        miss_df[‘mileage’] = miss_df[‘mileage’].fillna(miss_df.groupby([‘fry_qcut’])[‘mileage’].transform(‘mean’))\n",
    "        miss_df[‘mileage’] = miss_df[‘mileage’].fillna(miss_df.groupby([‘general_inspection_new’])[‘mileage’].transform(‘mean’))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Functions for filling missing values\n",
    "def fill_most(df, group_col, col_name):\n",
    "    for group in list(df[group_col].unique()):\n",
    "        cond = df[group_col]==group\n",
    "        grp_inx = list(df[cond][col_name].index)\n",
    "        mode = list(df[cond][col_name].mode())\n",
    "        if mode != []:\n",
    "            df[col_name].iloc[grp_inx] = df[col_name].iloc[grp_inx].fillna(df[cond][col_name].mode()[0])\n",
    "        else:\n",
    "            df[col_name].iloc[grp_inx] = df[col_name].iloc[grp_inx].fillna(df[col_name].mode()[0])\n",
    "def fill(df, group_col1, group_col2, col_name, method): # method can be “mode” or “median” or “ffill/bfill”\n",
    "    if method == “mode”:\n",
    "        for group1 in list(df[group_col1].unique()):\n",
    "            for group2 in list(df[group_col2].unique()):\n",
    "                cond1 = df[group_col1]==group1\n",
    "                cond2 = (df[group_col1]==group1) & (df[group_col2]==group2)\n",
    "                grp_inx = list(df[cond2][col_name].index)\n",
    "                mode1 = list(df[cond1][col_name].mode())\n",
    "                mode2 = list(df[cond2][col_name].mode())\n",
    "                if (mode1 != []) and (mode2 != []):\n",
    "                    df[col_name].iloc[grp_inx] = df[col_name].iloc[grp_inx].fillna(df[cond2][col_name].mode()[0]).fillna(df[cond1][col_name].mode()[0])\n",
    "                elif mode1 != []:\n",
    "                    df[col_name].iloc[grp_inx] = df[col_name].iloc[grp_inx].fillna(df[cond1][col_name].mode()[0])\n",
    "                else:\n",
    "                    df[col_name].iloc[grp_inx] = df[col_name].iloc[grp_inx].fillna(df[col_name].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
